{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28053,
     "status": "ok",
     "timestamp": 1606920604726,
     "user": {
      "displayName": "T Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8r3NKQ8rlZ5Wpd3qK9RlB-6AAoNbyGhplqh6NOw=s64",
      "userId": "12262433605380806472"
     },
     "user_tz": 300
    },
    "id": "FA1Y5VCv20XZ",
    "outputId": "0d8c918f-0095-4475-b452-eafeb0b7a9d3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import gym\n",
    "import math\n",
    "from itertools import count\n",
    "import time\n",
    "import sys\n",
    "import collections\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import COMPLEX_MOVEMENT, SIMPLE_MOVEMENT\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1361,
     "status": "ok",
     "timestamp": 1606920606095,
     "user": {
      "displayName": "T Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8r3NKQ8rlZ5Wpd3qK9RlB-6AAoNbyGhplqh6NOw=s64",
      "userId": "12262433605380806472"
     },
     "user_tz": 300
    },
    "id": "krW2sJVMo0Nw",
    "outputId": "889e7c6f-62be-4746-b51f-201157cd20fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0, 255, (240, 256, 3), uint8)\n"
     ]
    }
   ],
   "source": [
    "# Checkout original env\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
    "\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 685,
     "status": "ok",
     "timestamp": 1606920610353,
     "user": {
      "displayName": "T Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8r3NKQ8rlZ5Wpd3qK9RlB-6AAoNbyGhplqh6NOw=s64",
      "userId": "12262433605380806472"
     },
     "user_tz": 300
    },
    "id": "nPi1lHINMuSu"
   },
   "outputs": [],
   "source": [
    "# Taken from with modfication (float  -> uint8  for memory efficiency)\n",
    "# https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/blob/master/Chapter06/lib/wrappers.py\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "\n",
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None, skip=4):\n",
    "        super(MaxAndSkipEnv, self).__init__(env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = collections.deque(maxlen=2)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for _ in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            self._obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
    "        return max_frame, total_reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self._obs_buffer.clear()\n",
    "        obs = self.env.reset()\n",
    "        self._obs_buffer.append(obs)\n",
    "        return obs\n",
    "\n",
    "\n",
    "class ProcessFrame128(gym.ObservationWrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(ProcessFrame128, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(128, 128, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return ProcessFrame128.process(obs)\n",
    "\n",
    "    @staticmethod\n",
    "    def process(frame):\n",
    "        if frame.size == 240 * 256 * 3:\n",
    "            img = np.reshape(frame, [240, 256, 3]).astype(np.float32)\n",
    "        else:\n",
    "            assert False, \"Unknown resolution.\"\n",
    "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
    "        resized_screen = cv2.resize(img, (128, 128), interpolation=cv2.INTER_AREA)\n",
    "        x_t = np.reshape(resized_screen, [128, 128, 1])\n",
    "        return x_t.astype(np.uint8)\n",
    "\n",
    "class BufferWrapper(gym.ObservationWrapper):\n",
    "    # def __init__(self, env, n_steps, dtype=np.float32):\n",
    "    def __init__(self, env, n_steps, dtype=np.uint8):\n",
    "        super(BufferWrapper, self).__init__(env)\n",
    "        self.dtype = dtype\n",
    "        old_space = env.observation_space\n",
    "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
    "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
    "\n",
    "    def reset(self):\n",
    "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
    "        return self.observation(self.env.reset())\n",
    "\n",
    "    def observation(self, observation):\n",
    "        self.buffer[:-1] = self.buffer[1:]\n",
    "        self.buffer[-1] = observation\n",
    "        return self.buffer\n",
    "\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(old_shape[-1], \n",
    "                                old_shape[0], old_shape[1]), dtype=np.uint8)\n",
    "        # self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], \n",
    "        #                         old_shape[0], old_shape[1]), dtype=np.float32)        \n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)\n",
    "\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.uint8) \n",
    "\n",
    "def wrap_env(env):\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    env = ProcessFrame128(env)\n",
    "    env = ImageToPyTorch(env)\n",
    "    env = BufferWrapper(env, 4)\n",
    "    return ScaledFloatFrame(env)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "executionInfo": {
     "elapsed": 1402,
     "status": "ok",
     "timestamp": 1606920622636,
     "user": {
      "displayName": "T Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8r3NKQ8rlZ5Wpd3qK9RlB-6AAoNbyGhplqh6NOw=s64",
      "userId": "12262433605380806472"
     },
     "user_tz": 300
    },
    "id": "8Ag1LpY8qKCa",
    "outputId": "6fccdf22-45c7-4e41-e78a-b59af2e66bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0, 255, (4, 128, 128), uint8)\n",
      "Discrete(7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checkout wrapped env\n",
    "t_env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
    "\n",
    "t_env = JoypadSpace(t_env, SIMPLE_MOVEMENT)\n",
    "t_env = wrap_env(t_env)\n",
    "fr = t_env.reset()\n",
    "plt.imshow(fr[3,:,:], cmap = \"Greys\")\n",
    "print(t_env.observation_space)\n",
    "print(t_env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1606920625036,
     "user": {
      "displayName": "T Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8r3NKQ8rlZ5Wpd3qK9RlB-6AAoNbyGhplqh6NOw=s64",
      "userId": "12262433605380806472"
     },
     "user_tz": 300
    },
    "id": "N4S1I9xWMkf3"
   },
   "outputs": [],
   "source": [
    "# Experience replay buffer\n",
    "Experience = collections.namedtuple('Experience', field_names=['state', 'action', 'reward', 'new_state', 'done'])\n",
    "\n",
    "class ExpBuffer:\n",
    "    def __init__(self, max_size):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def push(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        idxs = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        states, actions, rewards, next_states, dones = zip(*[self.buffer[i] for i in idxs])\n",
    "        return np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1606920627830,
     "user": {
      "displayName": "T Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8r3NKQ8rlZ5Wpd3qK9RlB-6AAoNbyGhplqh6NOw=s64",
      "userId": "12262433605380806472"
     },
     "user_tz": 300
    },
    "id": "taYi5LZnIOqz"
   },
   "outputs": [],
   "source": [
    "# Taken from \n",
    "# https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On/blob/master/Chapter06/lib/dqn_model.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "        return self.fc(conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1606920631437,
     "user": {
      "displayName": "T Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8r3NKQ8rlZ5Wpd3qK9RlB-6AAoNbyGhplqh6NOw=s64",
      "userId": "12262433605380806472"
     },
     "user_tz": 300
    },
    "id": "jUZOyWrpra9z",
    "outputId": "4c9d6631-412b-4c5f-8e41-05743ff8db77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0, 255, (4, 128, 128), uint8)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 31, 31]           8,224\n",
      "              ReLU-2           [-1, 32, 31, 31]               0\n",
      "            Conv2d-3           [-1, 64, 14, 14]          32,832\n",
      "              ReLU-4           [-1, 64, 14, 14]               0\n",
      "            Conv2d-5           [-1, 64, 12, 12]          36,928\n",
      "              ReLU-6           [-1, 64, 12, 12]               0\n",
      "            Linear-7                  [-1, 512]       4,719,104\n",
      "              ReLU-8                  [-1, 512]               0\n",
      "            Linear-9                    [-1, 7]           3,591\n",
      "================================================================\n",
      "Total params: 4,800,679\n",
      "Trainable params: 4,800,679\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 0.81\n",
      "Params size (MB): 18.31\n",
      "Estimated Total Size (MB): 19.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Checkout the network\n",
    "t_env.reset()\n",
    "print(t_env.observation_space)\n",
    "\n",
    "net = DQN(t_env.observation_space.shape, t_env.action_space.n )\n",
    "\n",
    "summary(net, input_size=t_env.observation_space.shape,  device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-vtBmLyAH5-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1606920639794,
     "user": {
      "displayName": "T Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8r3NKQ8rlZ5Wpd3qK9RlB-6AAoNbyGhplqh6NOw=s64",
      "userId": "12262433605380806472"
     },
     "user_tz": 300
    },
    "id": "BCBQhXLfNeUG"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DQNAgent:\n",
    "    \n",
    "    def __init__(self, env, buffer_size=100000):\n",
    "        self.env = env\n",
    "        self.replay_buffer = ExpBuffer(max_size=buffer_size)\n",
    "        self.reset()\n",
    "        self.device = \"cpu\"\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda\"\n",
    "\n",
    "        self.model = DQN(env.observation_space.shape, env.action_space.n).to(self.device)\n",
    "        self.target_model = DQN(env.observation_space.shape, env.action_space.n).to(self.device)\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        self.target_model.eval()\n",
    "        # self.optimizer = torch.optim.RMSprop(self.model.parameters(), lr = 1e-4 )\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.00025)\n",
    "\n",
    "        self.loss_func =  nn.SmoothL1Loss()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total_reward = 0.0\n",
    "        self.state = self.env.reset()\n",
    "        \n",
    "    def play(self, eps):\n",
    "        # random sample action\n",
    "        action = 0\n",
    "        if(np.random.random() < eps):\n",
    "            action = self.env.action_space.sample()\n",
    "        # choose action with highest Q value\n",
    "        else:\n",
    "            state_tensor = torch.FloatTensor(self.state.astype(np.float32) / 255.0).unsqueeze(0).to(self.device)\n",
    "            # state_tensor = torch.FloatTensor(self.state).unsqueeze(0).to(self.device)\n",
    "            qvals_tensor = self.model(state_tensor)\n",
    "            action = int(np.argmax(qvals_tensor.cpu().detach().numpy()))\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "        experience = Experience(self.state, action, reward, next_state, done)\n",
    "\n",
    "        self.replay_buffer.push(experience)\n",
    "        self.state = next_state\n",
    "        self.total_reward += reward\n",
    "        if(done):\n",
    "            res_reward = self.total_reward\n",
    "            self.reset()\n",
    "            return res_reward\n",
    "        else:\n",
    "            return None\n",
    "    def load_params(self, file_name):\n",
    "        print(self.model.load_state_dict(torch.load(file_name)))\n",
    "    def copy_to_target(self):\n",
    "        print(\"Copying to target\")\n",
    "        self.target_model.load_state_dict(self.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "executionInfo": {
     "elapsed": 797,
     "status": "ok",
     "timestamp": 1606920643942,
     "user": {
      "displayName": "T Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8r3NKQ8rlZ5Wpd3qK9RlB-6AAoNbyGhplqh6NOw=s64",
      "userId": "12262433605380806472"
     },
     "user_tz": 300
    },
    "id": "KvvYReiBlJMT"
   },
   "outputs": [],
   "source": [
    "def train_model(agent, max_episodes, writer, expected_reward = 150, replay_start = 16384, batch_size = 32, gamma = 0.99, update_inverval = 1000, eps_start = 0.9, eps_end = 0.05, eps_decay = 0.999999):\n",
    "    episode_rewards = []\n",
    "    eps = eps_start\n",
    "    # Total steps played \n",
    "    total_steps = 0\n",
    "    best_mean_reward = 1000.0\n",
    "    \n",
    "    model_no = 0\n",
    "    for episode in range(max_episodes):\n",
    "    \n",
    "        for step in count():\n",
    "            total_steps += 1\n",
    "            eps = max(eps*eps_decay, eps_min)\n",
    "\n",
    "            episode_reward = agent.play(eps)\n",
    "            if(episode_reward is not None):\n",
    "                episode_rewards.append(episode_reward)\n",
    "                mean_reward = np.mean(episode_rewards[-100:])\n",
    "                writer.add_scalar(\"epsilon\", eps, total_steps)\n",
    "                writer.add_scalar(\"last_100_reward\", mean_reward, total_steps)\n",
    "                writer.add_scalar(\"reward\", episode_reward, total_steps)\n",
    "                if(mean_reward > best_mean_reward and total_steps > replay_start):\n",
    "                    best_mean_reward = mean_reward\n",
    "                    # save the most recent 10 best models\n",
    "                    torch.save(agent.model.state_dict(), \"Local_DQN_Mario_no\" + str(model_no))\n",
    "                    print(\"Best mean reward updated, model saved\")\n",
    "                    model_no += 1\n",
    "                    model_no = model_no % 10\n",
    "                print(\"%d:  %d games, mean reward %.3f, epsilon %.2f\" % (total_steps, episode, mean_reward, eps))\n",
    "                break\n",
    "            # start training only where there are enough data in replay buffer\n",
    "            if len(agent.replay_buffer) < replay_start:\n",
    "                continue\n",
    "            batch = agent.replay_buffer.sample(batch_size)\n",
    "            # Get a batch of exp from exp replay buffer\n",
    "            states, actions, rewards, next_states, dones = batch\n",
    "            states_tensor = torch.tensor(states.astype(np.float32) / 255.0, dtype=torch.float32).to(agent.device)\n",
    "            # states_tensor = torch.tensor(states, dtype=torch.float32).to(agent.device)\n",
    "            # must choose torch.LongTensor for actions, since index for gather function must be of int64\n",
    "            actions_tensor = torch.tensor(actions, dtype=torch.long).to(agent.device)\n",
    "            rewards_tensor = torch.tensor(rewards, dtype=torch.float32).to(agent.device)\n",
    "            next_states_tensor = torch.tensor(next_states.astype(np.float32) / 255.0, dtype=torch.float32).to(agent.device)\n",
    "            # next_states_tensor = torch.tensor(next_states, dtype=torch.float32).to(agent.device)\n",
    "            dones_tensor = torch.BoolTensor(dones).to(agent.device)\n",
    "            # print('+++++++')\n",
    "            # print(states_tensor.shape)\n",
    "            # print(actions_tensor.shape)\n",
    "            # print(rewards_tensor.shape)\n",
    "            # print(next_states_tensor.shape)\n",
    "            # print(dones_tensor.shape)\n",
    "            # get current Q value from the training network given the current action\n",
    "            curr_Q = agent.model(states_tensor).gather(1, actions_tensor.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "            # get expected Q value for all possible actions using the target net, and pick the highest Qval, e = reward + gamma * Q'(s_next)\n",
    "            max_next_Q = agent.target_model(next_states_tensor).max(1)[0]\n",
    "            # if it's final state, i.e done = True, the next_Q = 0\n",
    "            max_next_Q[dones_tensor] = 0.0\n",
    "            expected_Q = rewards_tensor + gamma * max_next_Q.detach()\n",
    "\n",
    "            loss = agent.loss_func(curr_Q, expected_Q)\n",
    "\n",
    "            agent.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            agent.optimizer.step()            \n",
    "\n",
    "\n",
    "\n",
    "            # Copy params to target net for every $update_inverval steps\n",
    "            if( total_steps % update_inverval == 0) :\n",
    "                agent.copy_to_target()\n",
    "            # Save a model every 250000 steps   \n",
    "            if (total_steps % 250000 == 0):\n",
    "                torch.save(agent.model.state_dict(), \"Local_DQN_Mario_snapshot\")\n",
    "                print(\"snapshot saved\")\n",
    "\n",
    "        if (best_mean_reward >= expected_reward):\n",
    "            break\n",
    "    writer.close()\n",
    "    return episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "executionInfo": {
     "elapsed": 9784,
     "status": "ok",
     "timestamp": 1606920659982,
     "user": {
      "displayName": "T Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8r3NKQ8rlZ5Wpd3qK9RlB-6AAoNbyGhplqh6NOw=s64",
      "userId": "12262433605380806472"
     },
     "user_tz": 300
    },
    "id": "lXuepxhRlJMT"
   },
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
    "\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "env = wrap_env(env)\n",
    "\n",
    "env.reset()\n",
    "replay_buffer_size = 100000          \n",
    "\n",
    "\n",
    "agent = DQNAgent(env, replay_buffer_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2548,
     "status": "ok",
     "timestamp": 1606920662563,
     "user": {
      "displayName": "T Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8r3NKQ8rlZ5Wpd3qK9RlB-6AAoNbyGhplqh6NOw=s64",
      "userId": "12262433605380806472"
     },
     "user_tz": 300
    },
    "id": "CbTrlboNbeUx",
    "outputId": "bc7002b1-fd87-4840-87fd-58fa7639ee61"
   },
   "outputs": [],
   "source": [
    "# agent.load_params(\"full_model_new_v5\")\n",
    "# agent.copy_to_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_episodes = 30\n",
    "\n",
    "gamma = 0.9                   \n",
    "batch_size = 32                \n",
    "update_interval = 10000    \n",
    "\n",
    "# early termination if reward reaches the following value\n",
    "expected_reward = 3000.0\n",
    "\n",
    "# start training after the following number steps\n",
    "replay_start = 100000\n",
    "\n",
    "eps_start=1.0\n",
    "eps_decay=0.9999975\n",
    "eps_min=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/' + str(math.floor(time.time())) + '-mario_1_1-' + str(eps_decay) + '-' + str(replay_buffer_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t5b14KGYlJMT",
    "outputId": "7c7be7e7-a3d6-4a7d-f6d8-13a1a4a3e66c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58:  0 games, mean reward 193.000, epsilon 1.00\n",
      "261:  1 games, mean reward 654.500, epsilon 1.00\n",
      "324:  2 games, mean reward 511.333, epsilon 1.00\n",
      "370:  3 games, mean reward 442.500, epsilon 1.00\n",
      "556:  4 games, mean reward 479.400, epsilon 1.00\n",
      "667:  5 games, mean reward 507.000, epsilon 1.00\n",
      "1701:  6 games, mean reward 558.143, epsilon 1.00\n",
      "2377:  7 games, mean reward 686.500, epsilon 0.99\n",
      "2421:  8 games, mean reward 635.333, epsilon 0.99\n",
      "2535:  9 games, mean reward 631.600, epsilon 0.99\n",
      "4254:  10 games, mean reward 641.000, epsilon 0.99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-ac629f323b11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mepisode_rewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_episodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpected_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplay_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate_interval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-108-5949373dc2e6>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(agent, max_episodes, writer, expected_reward, replay_start, batch_size, gamma, update_inverval, eps_start, eps_end, eps_decay)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meps_decay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps_min\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mepisode_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode_reward\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mepisode_rewards\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode_reward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-107-d57d9459807d>\u001b[0m in \u001b[0;36mplay\u001b[1;34m(self, eps)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mqvals_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqvals_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mexperience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExperience\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-102-5e72e8bc565f>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obs_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\nes_py\\wrappers\\joypad_space.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \"\"\"\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# take the step and record the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_action_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\nes_py\\nes_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrollers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[1;31m# pass the action to the emulator as an unsigned byte\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[1;31m# get the reward for this step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "episode_rewards = train_model(agent, max_episodes, writer, expected_reward, replay_start, batch_size, gamma, update_interval, eps_start, eps_min, eps_decay)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DQN_Atari_Breakout_uint8.ipynb",
   "provenance": [
    {
     "file_id": "10R0F_QX9RdTegTsdHtmYC88dGNMtAqb_",
     "timestamp": 1606664155707
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
